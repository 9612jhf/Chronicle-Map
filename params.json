{"name":"Chronicle-map","tagline":"Chronicle Map","body":"*We can help you get Chronicle up and running in your organisation, we suggest you invite us in for\r\nconsultancy, charged on an ad-hoc basis, we can discuss the best options tailored to your individual\r\nrequirements. - [Contact Us](sales@higherfrequencytrading.com)*\r\n\r\n*Or you may already be using Chronicle and just want some help - [find out more..](http://openhft.net/support/)*\r\n\r\n# Chronicle Map\r\n\r\nReplicate your Key Value Store across your network, with consistency, durability and performance.\r\n![Chronicle Map](http://openhft.net/wp-content/uploads/2014/07/ChronicleMap_200px.png)\r\n#### Maven Artifact Download\r\n```xml\r\n<dependency>\r\n  <groupId>net.openhft</groupId>\r\n  <artifactId>chronicle-map</artifactId>\r\n  <version><!--replace with the latest version--></version>\r\n</dependency>\r\n```\r\nClick here to get the [Latest Version Number](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22net.openhft%22%20AND%20a%3A%22chronicle-map%22) \r\n\r\n#### Contents\r\n\r\n* [Should I use Chronicle Queue or Chronicle Map](https://github.com/OpenHFT/Chronicle-Map#should-i-use-chronicle-queue-or-chronicle-map)\r\n* [What is the difference between SharedHashMap and Chronicle Map](https://github.com/OpenHFT/Chronicle-Map#what-is-the-difference-between-sharedhashmap-and-chronicle-map)\r\n* [Overview](https://github.com/OpenHFT/Chronicle-Map#overview)\r\n* [JavaDoc](http://openhft.github.io/Chronicle-Map/apidocs)\r\n* [Getting Started Guide](https://github.com/OpenHFT/Chronicle-Map#getting-started)\r\n *  [Simple Construction](https://github.com/OpenHFT/Chronicle-Map#simple-construction)\r\n *  [Sharing Data Between Two or More Maps](https://github.com/OpenHFT/Chronicle-Map#sharing-data-between-two-or-more-maps)\r\n *   [Entries](https://github.com/OpenHFT/Chronicle-Map#entries)\r\n *   [Size of Space Reserved on Disk](https://github.com/OpenHFT/Chronicle-Map#size-of-space-reserved-on-disk)\r\n *   [Chronicle Map Interface](https://github.com/OpenHFT/Chronicle-Map#chronicle-map-interface)\r\n* [Oversized Entries Support] (https://github.com/OpenHFT/Chronicle-Map/blob/master/README.md#oversized-entries-support)  \r\n* [Serialization](https://github.com/OpenHFT/Chronicle-Map#serialization)\r\n  *   [Simple Types](https://github.com/OpenHFT/Chronicle-Map#simple-types)\r\n  *   [Complex Types](https://github.com/OpenHFT/Chronicle-Map#complex-types)\r\n* [Close](https://github.com/OpenHFT/Chronicle-Map#close)\r\n* [TCP / UDP Replication](https://github.com/OpenHFT/Chronicle-Map#tcp--udp-replication)\r\n * [TCP / UDP Background.](https://github.com/OpenHFT/Chronicle-Map#tcp--udp-background)\r\n *   [How to setup UDP Replication](https://github.com/OpenHFT/Chronicle-Map#how-to-setup-udp-replication)\r\n *  [TCP/IP Throttling](https://github.com/OpenHFT/Chronicle-Map#tcpip--throttling)\r\n *   [Replication How it works](https://github.com/OpenHFT/Chronicle-Map#replication-how-it-works)\r\n *  [Multiple Chronicle Maps on a the same server with Replication](https://github.com/OpenHFT/Chronicle-Map#multiple-chronicle-maps-on-a-the-same-server-with-replication)\r\n *   [Identifier for Replication](https://github.com/OpenHFT/Chronicle-Map#identifier-for-replication)\r\n *   [Bootstrapping](https://github.com/OpenHFT/Chronicle-Map#bootstrapping)\r\n *      [Identifier](https://github.com/OpenHFT/Chronicle-Map#identifier)\r\n * [Port](https://github.com/OpenHFT/Chronicle-Map#port)\r\n * [Heart Beat Interval](https://github.com/OpenHFT/Chronicle-Map#heart-beat-interval)\r\n* [Clustering](https://github.com/OpenHFT/Chronicle-Map#cluster)\r\n  \r\n#### Miscellaneous\r\n\r\n * [Known Issues](https://github.com/OpenHFT/Chronicle-Map#known-issues)\r\n * [Stackoverflow](http://stackoverflow.com/tags/chronicle/info)\r\n * [Development Tasks - JIRA] (https://higherfrequencytrading.atlassian.net/browse/HCOLL)\r\n * [Use Case Which include Chronicle Map] (http://openhft.net/products/chronicle-engine/)\r\n\r\n#### Examples\r\n\r\n * [Hello World - A map which stores data off heap](https://github.com/OpenHFT/Chronicle-Map/blob/master/README.md#example--simple-hello-world)\r\n * [Sharing the map between two ( or more ) processes on the same computer](https://github.com/OpenHFT/Chronicle-Map/blob/master/README.md#example--sharing-the-map-on-two--or-more--processes-on-the-same-machine)\r\n * [Replicating data between process on different servers with TCP/IP Replication](https://github.com/OpenHFT/Chronicle-Map/blob/master/README.md#example--replicating-data-between-process-on-different-servers-via-tcp)\r\n * [Replicating data between process on different servers with UDP] (https://github.com/OpenHFT/Chronicle-Map/blob/master/README.md#example--replicating-data-between-process-on-different-servers-using-udp)\r\n *  [Creating a Chronicle Set and adding data to it](https://github.com/OpenHFT/Chronicle-Map/blob/master/README.md#example--creating-a-chronicle-set-and-adding-data-to-it)\r\n\r\n\r\n#### Performance Topics\r\n\r\n* [Chronicle Map with Large Data ](https://github.com/OpenHFT/Chronicle-Map#chronicle-map-with-large-data)\r\n* [Better to use small keys](https://github.com/OpenHFT/Chronicle-Map#better-to-use-small-keys)\r\n* [ConcurrentHashMap v ChronicleMap](https://github.com/OpenHFT/Chronicle-Map#concurrenthashmap-v-chroniclemap)\r\n\r\n\r\n### Overview\r\nChronicle Map implements the `java.util.concurrent.ConcurrentMap`, however unlike the standard\r\njava map, ChronicleMap is able to share your entries accross processes:\r\n\r\n\r\n![](http://openhft.net/wp-content/uploads/2014/07/Chronicle-Map-diagram_04.jpg)\r\n\r\n## When to use\r\n#### When to use HashMap\r\nIf you compare `HashMap`, `ConcurrentHashMap` and `ChronicleMap`, most of the maps in your system\r\nare likely to be HashMap.  This is because `HashMap` is lightweight and synchronized HashMap works\r\nwell for lightly contended use cases.  By contention I mean, how many threads on average are trying\r\nto use a Map.  One reason you can't have many contended resources, is that you only have so many\r\nCPUs and they can only be accessing so many resources at once (ideally no more than one or two\r\nper thread at a time).\r\n\r\n####  When to use ConcurrentHashMap\r\n`ConcurrentHashMap` scales very well when highly contended.  It uses more memory but if you only\r\nhave a few of them, this doesn't matter.  They have higher throughput than the other two solutions,\r\nbut also it creates the highest garbage.  If garbage pressure is an issue for you, you may want\r\nto consider `ChronicleMap`\r\n\r\nOne of the main differences between chronicle and ConcurrentHashMap, is how you go about creating\r\nan instance see the getting started guide below for details.\r\n\r\n####  When to use Chronicle Map\r\nIf you have;\r\n* lots of small key-values\r\n* you want to minimise garbage produced, and medium lived objects.\r\n* you need to share data between JVMs\r\n* you need persistence\r\n\r\n#### Should I use Chronicle Queue or Chronicle Map\r\nChronicle queue is designed to send every update. If your network can't do this something has\r\nto give. You could compress the data but at some point you have to work within the limits of your\r\nhardware or get more hardware. Chronicle Map on the other hand sends the latest value only.\r\nThis will naturally drop updates and is a more natural choice for low bandwidth connections.\r\n\r\n#### What is the difference between [SharedHashMap](https://github.com/OpenHFT/HugeCollections) and Chronicle Map\r\nSharedHashMap is an outdated version of ChronicleMap project.\r\nEffectively SharedHashMap has just been renamed to ChronicleMap, to further enrich the Chronicle\r\nproduct suite. In addition, The original Chronicle has been renamed to Chronicle Queue.\r\n\r\n\r\n## Getting Started\r\n\r\n### Simple Construction\r\n\r\nTo download the JAR which contains Chronicle Map, we recommend you use maven, which will download it\r\nfrom [Maven Central](http://search.maven.org), once you have installed maven, all you have to do is\r\nadd the following to your projects `pom.xml`:\r\n\r\n#### Maven Artifact Download\r\n```xml\r\n<dependency>\r\n  <groupId>net.openhft</groupId>\r\n  <artifactId>chronicle-map</artifactId>\r\n  <version><!--replace with the latest version--></version>\r\n</dependency>\r\n```\r\nTo get the latest version number\r\n[Click Here](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22net.openhft%22%20AND%20a%3A%22chronicle-map%22) \r\n\r\nwhen you add ( the above dependency ) to your pom maven will usually attempt to download the release artifacts from: \r\n```\r\nhttp://repo1.maven.org/maven2/net/openhft/chronicle-map\r\n```\r\n\r\n#### Maven Snapshot Download\r\nIf you want to try out the latest pre-release code, you can download the snapshot artifact manually from: \r\n```xml\r\nhttps://oss.sonatype.org/content/repositories/snapshots/net/openhft/chronicle-map/\r\n```\r\na better way is to add the following to your setting.xml, to allow maven to download snapshots :\r\n\r\n```xml\r\n<repository>\r\n    <id>Snapshot Repository</id>\r\n    <name>Snapshot Repository</name>\r\n    <url>https://oss.sonatype.org/content/repositories/snapshots</url>\r\n    <snapshots>\r\n        <enabled>true</enabled>\r\n    </snapshots>\r\n</repository>\r\n```\r\nand define the snapshot version in your pom.xml, for example:\r\n```xml\r\n<dependency>\r\n  <groupId>net.openhft</groupId>\r\n  <artifactId>chronicle-map</artifactId>\r\n  <version>1.0.1-SNAPSHOT</version>\r\n</dependency>\r\n```\r\n#### Java Class Construction\r\n\r\nCreating an instance of Chronicle Map is a little more complexed than just calling a constructor.\r\nTo create an instance you have to use the ChronicleMapBuilder.\r\n\r\n``` java\r\nimport net.openhft.chronicle.map.*\r\n.....\r\n\r\ntry {\r\n\r\n    String tmp = System.getProperty(\"java.io.tmpdir\");\r\n    String pathname = tmp + \"/shm-test/myfile.dat\";\r\n\r\n    File file = new File(pathname);\r\n\r\n    ChronicleMapBuilder<Integer, CharSequence> builder =\r\n        ChronicleMapBuilder.of(Integer.class, CharSequence.class);\r\n    ConcurrentMap<Integer, CharSequence> map = builder.create(file);\r\n \r\n} catch (IOException e) {\r\n    e.printStackTrace();\r\n}\r\n```\r\n\r\nChronicle Map stores its data off the java heap, If you wish to share this off-heap memory between\r\nprocesses on the same server, you must provide a \"file\", this file must be the same \"file\" for all\r\nthe instances of Chronicle Map on the same server. The name and location of the \"file\" is entirely\r\nup to you.  For the best performance on many unix systems we recommend using\r\n[tmpfs](http://en.wikipedia.org/wiki/Tmpfs).\r\n\r\nIf instead, you do not wish to replicate between process on the same server or if you are only\r\nusing TCP replication to replicate between servers, you do not have to provide the \"file\",\r\nso you can call `create()` method on ChronicleMapBuilder without file parameter:\r\n```\r\nConcurrentMap<Integer, CharSequence> map = builder.create();\r\n```\r\n\r\n### Sharing Data Between Two or More Maps\r\nSince this file is memory mapped, if you were to create another instance of the Chronicle Map,\r\npointing to the same file, both Chronicle Maps use this file as a common memory store, which they\r\nboth read and write into. The good thing about this is the two ( or more instances of the Chronicle Map )\r\ndon't have to be running in the same java process. Ideally and for best performance, the two processes\r\nshould be running on the same server. Since the file is memory mapped, ( in most cases ) the read\r\nand writes to the file are hitting the disk cache. Allowing the chronicle map to exchange data\r\nbetween processes by just using memory and in around 40 nanoseconds. \r\n\r\n``` java \r\nConcurrentMap<Integer, CharSequence> map1, map2;\r\n\r\n// this could could be on one process\r\nmap1 = ChronicleMapBuilder.of(Integer.class, CharSequence.class).create(file);\r\n\r\n// this could be on the other process\r\nmap2 = ChronicleMapBuilder.of(Integer.class, CharSequence.class).create(file);\r\n```\r\nNote: In order to share data between map1 and map2, the file has to point to the same file location\r\non your server.\r\n\r\n### Entries\r\n\r\nOne of the differences with Chronicle Map against ConcurrentHashMap, is that it can't be resized,\r\nunlike the ConcurrentHashMap, Chronicle Map is not limited to the available on heap memory.\r\nResizing is a very expensive operation for Hash Maps, as it can stall your application, so as such\r\nwe don't do it. When you are building a Chronicle Map you can set the maximum number of entries that\r\nyou are ever likely to support, its ok to over exaggerate this number. As the Chronicle Map is not\r\nlimited to your available memory, At worst you will end up having a very large file on disk.\r\n\r\nYou set the maximum number of entries by the builder:\r\n\r\n``` java\r\nConcurrentMap<Integer, CharSequence> map =\r\n    ChronicleMapBuilder.of(Integer.class, CharSequence.class)\r\n    .entries(1000) // set the max number of entries here\r\n    .create(file);\r\n```\r\nIn this example above we have set 1000 entries.\r\n\r\nWe have optimised chronicle, So that you can have situations where you either don't use;\r\n\r\n- all the entries you have allowed for.  This works best on Unix where the disk space and memory used reflect the number of actual entries, not the number you allowed for.\r\n\r\n- all the space you allow for each entry.  This helps if you have entries which are multiple cache lines (128 bytes +), only the lines you touch sit in your CPU cache and if you have multiple pages (8+ Kbytes) only the pages you touch use memory or disk.  The CPU cache usage matters as it can be 10000x smaller than main memory.\r\n\r\n### Size of space reserved on disk\r\n\r\nIn linux, if you looked at the size of the 'file', it will report the used entry size so if you\r\nhave just added one entry, it will report the size of this entry, but Windows will report\r\nthe reserved size, as it reserves the disk space eagerly ( in fact windows also reserves the memory\r\neagerly as well ) in other words number-of-entries x entry-size. \r\n\r\nso on linux, if your type\r\n``` \r\n# It shows you the extents. \r\nls -l <file>\r\n\r\n# It shows you how much is actually used.\r\ndu <file>\r\n```\r\n\r\nTo illustrate this with an example - On Ubuntu we can create a 100 TB chronicle map.  Both `top` and\r\n`ls -l` say the process virtual size / file size is 100 TB, however the resident memory via `du`\r\nsays the size is 71 MB after adding 10000 entries. You can see the size actually used with du.\r\n\r\n\r\n### Chronicle Map Interface \r\nThe Chronicle Map interface adds a few methods above an beyond the standard ConcurrentMap,\r\nthe ChronicleMapBuilder can also be used to return the ChronicleMap, see the example below :\r\n\r\n``` java\r\nChronicleMap<Integer, CharSequence> map =\r\n    ChronicleMapBuilder.of(Integer.class, CharSequence.class).create(file);\r\n```\r\nOne way to achieve good performance is to focus on unnecessary object creation as this reduces\r\nthe amount of work that has to be carried out by the Garbage Collector. As such ChronicleMap\r\nsupports the following methods :\r\n\r\n - [`V getUsing(K key, V value);`](http://openhft.github.io/Chronicle-Map/apidocs/net/openhft/chronicle/map/ChronicleMap.html#getUsing-K-V-)\r\n - [`V acquireUsing(K key, V value);`](http://openhft.github.io/Chronicle-Map/apidocs/net/openhft/chronicle/map/ChronicleMap.html#acquireUsing-K-V-)\r\n\r\nThese methods let you provide the object which the data will be written to, even if the object it\r\nimmutable. For example \r\n\r\n``` java\r\nStringBuilder myString = new StringBuilder(); \r\nStringBuilder myResult = map.getUsing(\"key\", myString);\r\n// at this point the myString and myResult will both point to the same object\r\n```\r\n\r\nThe `map.getUsing()` method is similar to `get()`, but because Chronicle Map stores its data off\r\nheap, if you were to call get(\"key\"), a new object would be created each time, map.getUsing() works\r\nby reusing the heap memory which was used by the original Object \"myString\". This technique provides\r\nyou with better control over your object creation.\r\n\r\nExactly like `map.getUsing()`, `acquireUsing()` will give you back a reference to an value based on\r\na key, but unlike `getUsing()` if there is not an entry in the map for this key the entry will be\r\nadded and the value return will we the same value which you provided.\r\n\r\n\r\n## Oversized Entries Support\r\n\r\nIt is possible for an entry to be twice as large as the maximum entry, we refer to this type of\r\nentry as an oversized entry. Oversized entries are there to cater for the case where only a small\r\npercentage of your entries are twise as large as the others, in this case your large entry will\r\nspan across two entries. The alternative would be to increase your maximum entry size to be similar\r\nto the size of the largest entry, but this approach is wasteful of memory, especially when most\r\nentries are no where near the max entry size.  \r\n\r\n## Serialization\r\n\r\nChronicle Map stores your data into off heap memory, so when you give it a Key or Value, it will\r\nserialise these objects into bytes.\r\n\r\n### Simple Types\r\nIf you are using simple auto boxed objects based on the primitive types, Chronicle Map will\r\nautomatically handle the serialisation for you.  \r\n\r\n### Complex Types\r\nFor anything other than the standard object, the Objects either have to :\r\n* implement \"java.io.Serializable\" ( which we don't recommend as this can be slow )\r\n* we also support \"java.io.Externalizable\", we recommend this over Serializable as its usually faster.\r\n* or for the best performance implement net.openhft.lang.io.serialization.BytesMarshallable,\r\nan example of how to do this can be found at \"IntValue$$Native\"\r\n* alternatively, you could write a \"Custom Marshaller\", the custom marshaller can be implemented\r\nfor a single type or a number of types.\r\n\r\n### Close\r\nUnlike ConcurrentHashMap, chronicle map stores its data off heap, often in a memory mapped file.\r\nIts recommended that you call close() once you have finished working with a Chronicle Map.\r\n``` java\r\nmap.close()\r\n```\r\nWARNING : If you call close too early before you have finished working with the map, this can cause\r\nyour JVM to crash. Close MUST BE the last thing that you do with the map.\r\n\r\n# TCP / UDP Replication\r\nChronicle Hash Map supports both TCP and UDP replication\r\n\r\n### TCP / UDP Background.\r\nTCP/IP is a reliable protocol, what this means is unless you have a network failure or hardware\r\noutage the data is guaranteed to arrive. TCP/IP provides point to point connectivity. So in effect\r\n( over simplified ), if the message was sent to 100 hosts, The message would have to be sent\r\n100 times. With UDP, the message is only sent once. This is ideal if you have a large number of\r\nhosts and you wish to broadcast the same data to each off them.   However, one of the big drawbacks\r\nwith UDP is its not a reliable protocol. This means, if the UDP message is Broadcast onto\r\nthe network, The hosts are not guaranteed to receive it, so they can miss data. Some solutions\r\nattempt to build resilience into UDP, but arguably, this is in effect reinventing TCP/IP.\r\n\r\n### How to setup UDP Replication\r\nIn reality on a good quality wired LAN, when using UDP, you will rarely miss messages, this is\r\na risk that we suggest you don't take. We suggest that whenever you use UDP replication you use it\r\nin conjunction with a throttled TCP replication, therefore if a host misses a message over UDP, they\r\nwill later pick it up via TCP/IP. \r\n\r\n###  TCP/IP  Throttling\r\nWe are careful not to swamp your network with too much TCP/IP traffic, We do this by providing\r\na throttled version of TCP replication. This works because Chronicle Map only broadcasts the latest\r\nupdate of each entry. \r\n\r\n### Replication How it works\r\n\r\nChronicle Map provides multi master hash map replication, What this means, is that each remote\r\nhash-map, mirrors its changes over to another remote hash map, neither hash map is considered\r\nthe master store of data, each hash map uses timestamps to reconcile changes.\r\nWe refer to in instance of a remote hash-map as a node.\r\nA node can be connected to up to 128 other nodes.\r\nThe data that is stored locally in each node becomes eventually consistent. So changes made to one\r\nnode, for example by calling put() will be replicated over to the other node. To achieve a high\r\nlevel of performance and throughput, the call to put() won’t block, \r\nWith concurrentHashMap, It is typical to check the return code of some methods to obtain the old\r\nvalue for example remove(). Due to the loose coupling and lock free nature of this multi master\r\nimplementation,  this return value is only the old value on the nodes local data store. In other\r\nwords the nodes are only concurrent locally. Its worth realising that another node performing\r\nexactly the same operation may return a different value. However reconciliation will ensure the maps\r\nthemselves become eventually consistent.\r\n\r\n### Reconciliation \r\nIf two ( or more nodes ) receive a change to their maps for the same key but different values, say\r\nby a user of the maps, calling the put(key,value). Then, initially each node will update its local\r\nstore and each local store will hold a different value, but the aim of multi master replication is\r\nto provide eventual consistency across the nodes. So, with multi master when ever a node is changed\r\nit will notify the other nodes of its change. We will refer to this notification as an event.\r\nThe event will hold a timestamp indicating the time the change occurred, it will also hold the state\r\ntransition, in this case it was a put with a key and value.\r\nEventual consistency is achieved by looking at the timestamp from the remote node, if for a given\r\nkey, the remote nodes timestamp is newer than the local nodes timestamp, then the event from\r\nthe remote node will be applied to the local node, otherwise the event will be ignored. Since\r\nnone of the nodes is a primary, each node holds information about the other nodes. For this node its\r\nown identifier is referred to as its 'localIdentifier', the identifiers of other nodes are the\r\n'remoteIdentifiers'. On an update or insert of a key/value, this node pushes the information of\r\nthe change to the remote nodes. The nodes use non-blocking java NIO I/O and all replication is done\r\non a single thread. However there is an edge case, If two nodes update their map at the same time\r\nwith different values, we had to deterministically resolve which update wins, because of eventual\r\nconsistency both nodes should end up locally holding the same data. Although it is rare two remote\r\nnodes could receive an update to their maps at exactly the same time for the same key, we had\r\nto handle this edge case, its therefore important not to rely on timestamps alone to reconcile\r\nthe updates. Typically the update with the newest timestamp should win, but in this example both\r\ntimestamps are the same, and the decision made to one node should be identical to the decision made\r\nto the other. This dilemma is resolved by using a node identifier, the node identifier is a unique\r\n'byte' value that is assigned to each node, So when the time stamps are the same if the remoteNodes\r\nidentifier is smaller than the local nodes identifier, this update will be accepted otherwise it\r\nwill be ignored.\r\n\r\n### Multiple Chronicle Maps on a the same server with Replication\r\nIf two or more Chronicle Maps are on the same server, they exchange data via shared memory rather\r\nthan TCP or UDP replication. So if a Chronicle Map which is not performing TCP Replication is\r\nupdated, this update can be picked up by another Chronicle Map, this other Chronicle Hash Map could\r\nbe a TCP replicated Chronicle Map, In this example the TCP replicated Chronicle Map would then push\r\nthe update to the remote nodes.\r\n\r\nLikewise, If the TCP replicated Chronicle Map was to received an update from a remote node, then\r\nthis update would be immediately available to all the Chronicle Maps on the server.\r\n\r\n### Identifier for Replication\r\nIf all you are doing is replicating your chronicle maps on the same server you don't have to set up\r\nTCP and UDP replication. You also don't have to set the identifiers. \r\n\r\nIf however you wish to replicate data between 2 or more servers, then ALL of the Chronicle Maps\r\nincluding those not actively participating in TCP or UDP replication must have the identifier set.\r\nThe identifier must be unique to each server. Each Chronicle Map on the same server must have\r\nthe same identifier. The reason that all Chronicle Maps must have the identifier set, is because\r\nthe memory is laid out slightly differently when using replication, so even if a Map is not actively\r\nperforming TCP or UDP replication its self, if it wishes to replicate with one that is, it must have\r\nits memory laid out the same way to be compatible. \r\n\r\nIf the identifiers are not set up uniquely then the updates will be ignored, as for example\r\na Chronicle Map set up with the identifiers equals '1', will ignore all events which contain\r\nthe remote identifier of '1', in other words Chronicle Map replication is set up to ignore updates\r\nwhich have originated from itself. This is to avoid the circularity of events.\r\n\r\nWhen setting up the identifier you can use values from 1 to 127. ( see the section above for more\r\ninformation on identifiers and how they are used in replication. )\r\n\r\nThe identifier is setup on the builder as follows.\r\n\r\n```java\r\nTcpReplicationConfig tcpConfig = ...\r\nmap = ChronicleMapBuilder\r\n    .of(Integer.class, CharSequence.class)\r\n    .addReplicator(Replicators.tcp(identifier, tcpConfig))\r\n    .create(file);\r\n```\r\n\r\n### Bootstrapping \r\nWhen a node is connected over the network to an active grid of nodes. It must first receive any data\r\nthat it does not have from the other nodes. Eventually, all the nodes in the grid have to hold a\r\ncopy of exactly the same data. We refer to this initial data load phase as bootstrapping.\r\nBootstrapping by its very nature is point to point, so it is only performed over TCP replication.\r\nFor architectures that wish to use UDP replication it is advised you use TCP Replication as well. A\r\ngrid which only uses UDP replication will miss out on the bootstrapping, possibly leaving the nodes\r\nin an inconsistent state. To avoid this, if you would rather reduce the amount of TCP traffic on\r\nyour network, we suggest you consider using a throttle TCP replication along with UDP replication.\r\nBootstrapping is not used when the nodes are on the same server, so for this case, TCP replication\r\nis not required.\r\n\r\n### Identifier\r\nEach map is allocated a unique identifier\r\n\r\nServer 1 has:\r\n```\r\n.addReplicator(Replicators.tcp((byte) 1, tcpConfig))\r\n```\r\n\r\nServer 2 has:\r\n```\r\n.addReplicator(Replicators.tcp((byte) 2, tcpConfig))\r\n```\r\nIf you fail to allocate a unique identifier replication will not work correctly.\r\n\r\n### Port\r\nEach map must be allocated a unique port, the port has to be unique per server, if the maps are\r\nrunning on different hosts they could be allocated the same port, but in our example we allocated\r\nthem different ports, we allocated map1 port 8076 and map2 port 8077. Currently we don't support\r\ndata forwarding, so it important to connect every remote map, to every other remote map, in other\r\nwords you can't have a hub configuration where all the data passes through a single map which every\r\nother map is connected to. So currently, if you had 4 servers each with a Chronicle Map, you would\r\nrequire 6 connections.\r\n\r\nIn our case we are only using 2 maps, this is how we connected map1 to map 2.\r\n```\r\nTcpReplicationConfig.of(8076, new InetSocketAddress(\"localhost\", 8077))\r\n                    .heartBeatInterval(1, SECONDS);\r\n```\r\nyou could have put this instruction on map2 instead, like this \r\n```\r\nTcpReplicationConfig.of(8077, new InetSocketAddress(\"localhost\", 8076))\r\n                    .heartBeatInterval(1, SECONDS);\r\n```\r\neven though data flows from map1 to map2 and map2 to map1 it doesn't matter which way you connected\r\nthis, in other words its a bidirectional connection. \r\n\r\n### Heart Beat Interval\r\nWe set a heartBeatInterval, in our example to 1 second\r\n``` java\r\n heartBeatInterval(1, SECONDS)\r\n```\r\nA heartbeat will only be send if no data is transmitted, if the maps are constantly exchanging data\r\nno heartbeat message is sent. If a map does not receive either data of a heartbeat the connection\r\nis dropped and re-established.\r\n\r\n# Cluster\r\n\r\nChronicle Map TCP Replication lets you distribute a single Chronicle Map, to a number of servers\r\nacross your network. Replication is point to point and the data transfer is bidirectional, so in the\r\nexample of just two servers, they only have to be connected via a single tcp socket connection and\r\nthe data is transferred both ways. Which is great, however what if you wanted to replicate more than\r\njust one chronicle map, what if you were going to replicate two chronicle maps across your network,\r\nunfortunately with just TCP replication you would have to have two tcp socket connections, which is\r\nnot ideal. This is why we created Chronicle Clustering. Clustering lets you replicate numerous\r\nChronicle Maps via a single point to point socket connection.\r\n\r\nClustering is similar to TCP replication, where each map has to be given a unique identifier, but\r\nwhen using Chronicle Clustering its the cluster that is given the unique identifier not the map.\r\n\r\n``` java\r\nReplicatingClusterBuilder clusterBuilder = new ReplicatingClusterBuilder((byte) 2, 1024);\r\n```\r\n\r\nIn this example above the cluster is given the identifier of 2\r\n\r\nIn addition to specifying the identifier we also have to set the maximum entry size, this sets\r\nthe size of the memory buffers within the cluster.  This has to be set manually, with clusters you\r\nare able to attach additional maps to a cluster once its up and running, so the maximum size of each\r\nentry in the map can not be known in advance and we don’t currently support automatic resizing\r\nof buffers.\r\n\r\nOnce you have created the cluster you should attach your tcpConfig\r\n``` java\r\nTcpReplicationConfig tcpConfig = TcpReplicationConfig.of(8087).heartBeatInterval(1, SECONDS);\r\nclusterBuilder.tcpReplication(tcpConfig);\r\nReplicatingCluster cluster = clusterBuilder.create();\r\n```\r\n\r\nAttaching cluster replication to the map:\r\n\r\n``` java\r\nChronicleMap<Integer, CharSequence> map = ChronicleMapBuilder.of(Integer.class, CharSequence.class)\r\n    .entries(1000)\r\n    .addReplicator(cluster.channelReplicator((short) 1))\r\n    .create(file);\r\n```\r\n\r\nThe chronicle channel is use to identify which map is to be replicated to which other map on\r\nthe remote node, in the example above this is assigned to '(short) 1', so for example if you have\r\ntwo maps, lets call them map1 and map2, you could assign them with chronicle\r\nchannels 1 and 2 respectively. Map1 would have the chronicle channel of 1 on both servers. You\r\nshould not confuse the Chronicle Channels with the identifiers, the identifiers are unique per\r\nreplicating node the chronicle channels are used to identify which map you are referring. No\r\nadditional socket connection is made per chronicle channel that you use, so we allow up to 32767\r\nchronicle channels.\r\n\r\nIf you inadvertently got the chronicle channels around the wrong way, then chronicle would attempt\r\nto replicate the wrong maps data. The chronicle channels don't have to be in order but they must be\r\nunique for each map you have.\r\n\r\nOnce you have created the cluster you may wish to hold onto the reference so that you can call close\r\nonce you have finished, this will close everything in the cluster \r\n\r\n``` java\r\ncluster.close();\r\n```\r\n\r\n####  Known Issues\r\n\r\n##### Memory issue on Windows\r\n\r\nChronicle map lets you assign a map larger than your available memory, If you were to create more\r\nentries than the available memory, chronicle map will page the segments that are accessed least to\r\ndisk, and load the recently used segments into available memory. This feature lets you work with\r\nextremely large maps, it works brilliantly on Linux but unfortunately, this paging feature is not\r\nsupported on Windows, if you use more memory than is physically available on windows you will\r\nexperience the following error :\r\n\r\n```java\r\nJava frames: (J=compiled Java code, j=interpreted, Vv=VM code)\r\nj sun.misc.Unsafe.compareAndSwapLong(Ljava/lang/Object;JJJ)Z+0\r\nj net.openhft.lang.io.NativeBytes.compareAndSwapLong(JJJ)Z+13\r\nj net.openhft.lang.io.AbstractBytes.tryLockNanos8a(JJ)Z+12\r\nj net.openhft.lang.io.AbstractBytes.tryLockNanosLong(JJ)Z+41\r\nj net.openhft.collections.AbstractVanillaSharedHashMap$Segment.lock()V+12\r\n```\r\n\r\n##### When Chronicle Map is Full\r\n\r\nIt will throw this exception :\r\n\r\n```java\r\nCaught: java.lang.IllegalStateException: VanillaShortShortMultiMap is full\r\njava.lang.IllegalStateException: VanillaShortShortMultiMap is full\r\n\tat net.openhft.collections.VanillaShortShortMultiMap.nextPos(VanillaShortShortMultiMap.java:226)\r\n\tat net.openhft.collections.AbstractVanillaSharedHashMap$Segment.put(VanillaSharedHashMap.java:834)\r\n\tat net.openhft.collections.AbstractVanillaSharedHashMap.put0(VanillaSharedHashMap.java:348)\r\n\tat net.openhft.collections.AbstractVanillaSharedHashMap.put(VanillaSharedHashMap.java:330)\r\n```\r\n\r\nChronicle Map doesn't resize automatically.  It is assumed you will make the virtual size of the map\r\nlarger than you need and it will handle this reasonably efficiently. With the default settings you\r\nwill run out of space between 1 and 2 million entries.\r\n\r\nYou should set the .entries(..) and .entrySize(..) to those you require.\r\n\r\n\r\n# Example : Simple Hello World\r\n\r\nThis simple chronicle map, works just like ConcurrentHashMap but stores its data off-heap. If you want to use Chronicle Map to share data between java process you should look at the next exampl \r\n\r\n``` java \r\nMap<Integer, CharSequence> map = ChronicleMapBuilder.of(Integer.class,\r\n        CharSequence.class).create();\r\n\r\nmap.put(1, \"hello world\");\r\nSystem.out.println(map.get(1));\r\n\r\n``` \r\n\r\n# Example : Sharing the map on two ( or more ) processes on the same machine\r\n\r\nLets assume that we had two server, lets call them server1 and server2, if we wished to share a map\r\nbetween them, this is how we could set it up\r\n\r\n``` java \r\n\r\n// --- RUN ON ONE JAVA PROCESS ( BUT ON THE SAME SERVER )\r\n{\r\n    File file = new File(\"a-new-file-on-your-sever\");\t\r\n    Map<Integer, CharSequence> map1 = ChronicleMapBuilder.of(Integer.class,\r\n            CharSequence.class).create(file); // this has to be the same file as used by map 2\r\n    map1.put(1, \"hello world\");\r\n}\r\n\r\n// --- RUN ON THE OTHER JAVA PROCESS ( BUT ON THE SAME SERVER )\r\n{\r\n    File file = new File(\"a-new-file-on-your-sever\");  // this has to be the same file as used by map 1\r\n    Map<Integer, CharSequence> map1 = ChronicleMapBuilder.of(Integer.class,\r\n            CharSequence.class).create(file);\r\n\r\n    System.out.println(map1.get(1));\r\n}\r\n```\r\n\r\n\r\n# Example : Replicating data between process on different servers via TCP\r\n\r\nLets assume that we had two server, lets call them server1 and server2, if we wished to share a map\r\nbetween them, this is how we could set it up\r\n\r\n``` java \r\nMap map1;\r\nMap map2;\r\n\r\n//  ----------  SERVER1 1 ----------\r\n{\r\n\r\n    // we connect the maps via a TCP socket connection on port 8077\r\n\r\n    TcpReplicationConfig tcpConfig = TcpReplicationConfig.of(8076, new InetSocketAddress(\"localhost\", 8077))\r\n            .heartBeatInterval(1L, SECONDS);\r\n    ChronicleMapBuilder<Integer, CharSequence> map1Builder =\r\n            ChronicleMapBuilder.of(Integer.class, CharSequence.class)\r\n                    .entries(20000L)\r\n                    .addReplicator(tcp((byte) 1, tcpConfig));\r\n\r\n\r\n    map1 = map1Builder.create();\r\n}\r\n//  ----------  SERVER2 on the same server as ----------\r\n\r\n{\r\n    TcpReplicationConfig tcpConfig = TcpReplicationConfig.of(8077)\r\n            .heartBeatInterval(1L, SECONDS);\r\n    ChronicleMapBuilder<Integer, CharSequence> map2Builder =\r\n            ChronicleMapBuilder.of(Integer.class, CharSequence.class)\r\n                    .entries(20000L)\r\n                    .addReplicator(tcp((byte) 2, tcpConfig));\r\n    map2 = map2Builder.create();\r\n\r\n    // we will stores some data into one map here\r\n    map2.put(5, \"EXAMPLE\");\r\n}\r\n\r\n//  ----------  CHECK ----------\r\n\r\n// we are now going to check that the two maps contain the same data\r\n\r\n// allow time for the recompilation to resolve\r\nint t = 0;\r\nfor (; t < 5000; t++) {\r\n    if (map1.equals(map2))\r\n        break;\r\n    Thread.sleep(1);\r\n}\r\n\r\nAssert.assertEquals(map1, map2);\r\nassertTrue(!map1.isEmpty());\r\n}\r\n```\r\n\r\n# Example : Replicating data between process on different servers using UDP\r\n\r\nThis example is the same as the one above, but it uses a slow throttled TCP/IP connection to fill in updates that may have been missed when sent over UDP. Usually on a good network, for example a wired LAN, UDP won’t miss updates. But UDP does not support guaranteed delivery, we recommend also running a TCP connection along side to ensure the data becomes eventually consistent.  Note : It is possible to use Chronicle without the TCP replication and just use UDP (  that’s if you like living dangerously ! )\r\n\r\n\r\n\r\n``` java \r\nMap map1;\r\nMap map2;\r\n\r\nint udpPort = 1234;\r\n\r\n//  ----------  SERVER1 1 ----------\r\n{\r\n\r\n    // we connect the maps via a TCP socket connection on port 8077\r\n\r\n    TcpReplicationConfig tcpConfig = TcpReplicationConfig.of(8076, new InetSocketAddress(\"localhost\", 8077))\r\n            .heartBeatInterval(1L, SECONDS)\r\n\r\n            // a maximum of 1024 bits per millisecond\r\n            .throttlingConfig(ThrottlingConfig.throttle(1024, TimeUnit.MILLISECONDS));\r\n\r\n\r\n    UdpReplicationConfig udpConfig = UdpReplicationConfig\r\n            .simple(Inet4Address.getByName(\"255.255.255.255\"), udpPort);\r\n\r\n    ChronicleMapBuilder<Integer, CharSequence> map1Builder =\r\n            ChronicleMapBuilder.of(Integer.class, CharSequence.class)\r\n                    .entries(20000L)\r\n                    .addReplicator(tcp((byte) 1, tcpConfig))\r\n                    .addReplicator(udp((byte) 1, udpConfig));\r\n\r\n\r\n    map1 = map1Builder.create();\r\n}\r\n//  ----------  SERVER2 2 on the same server as ----------\r\n\r\n{\r\n    TcpReplicationConfig tcpConfig = TcpReplicationConfig.of(8077)\r\n            .heartBeatInterval(1L, SECONDS)\r\n            .throttlingConfig(ThrottlingConfig.throttle(1024, TimeUnit.MILLISECONDS));\r\n\r\n    UdpReplicationConfig udpConfig = UdpReplicationConfig\r\n            .simple(Inet4Address.getByName(\"255.255.255.255\"), udpPort);\r\n\r\n    ChronicleMapBuilder<Integer, CharSequence> map2Builder =\r\n            ChronicleMapBuilder.of(Integer.class, CharSequence.class)\r\n                    .entries(20000L)\r\n                    .addReplicator(tcp((byte) 2, tcpConfig))\r\n                    .addReplicator(udp((byte) 1, udpConfig));\r\n\r\n    map2 = map2Builder.create();\r\n\r\n    // we will stores some data into one map here\r\n    map2.put(5, \"EXAMPLE\");\r\n}\r\n\r\n//  ----------  CHECK ----------\r\n\r\n// we are now going to check that the two maps contain the same data\r\n\r\n// allow time for the recompilation to resolve\r\nint t = 0;\r\nfor (; t < 5000; t++) {\r\n    if (map1.equals(map2))\r\n        break;\r\n    Thread.sleep(1);\r\n}\r\n\r\nAssert.assertEquals(map1, map2);\r\nassertTrue(!map1.isEmpty());\r\n}\r\n```\r\n\r\n# Example : Creating a Chronicle Set and adding data to it\r\n\r\nThis project also provideds the Chronicle Set, Chronicle Set is built on Chronicle Map, so the builder configuration are almost identical to Chronicle Map ( see above ), this example shows how to create a simple off heap set\r\n``` java \r\n        Set<Integer> set = ChronicleSetBuilder.of(Integer.class).create();\r\n        \r\n        set.add(1);\r\n        set.remove(1)\r\n```\r\nand just like map it support shared memory and TCP replication.         \r\n        \r\n        \r\n# Performance Topics\r\n\r\n### Tuning Chronicle Map with Large Data \r\n\r\nGenerally speaking Chronicle Map is slower then ConcurrentHashMap for a small number of entries, but\r\nfor a large number of entries ConcurrentHashMap doesn't scale as well as Chronicle Map, especially\r\nwhen you start running low on heap. ConcurrentHashMap quickly becomes unusable whereas Chronicle Map\r\ncan still work when it is 20 times the size of a ConcurrentHashMap with an Out of Memory Error.\r\n  \r\nFor example with a heap of 3/4 of say 32 GB main memory, you might get say 100 million entries but\r\nwhen using most of the heap you might see 20-40 second gc pauses with Chronicle Map you could have\r\n1000 million entries and see < 100 ms pauses (depending on your disk subsystem and how fast you\r\nwrite your data)\r\n\r\nChronicle Map makes heavy use of the OS to perform the memory management and writing to disk. How it\r\nbehaves is very dependant on how you tune the kernel and what hardware you are using. You may get\r\nbad behaviour when the kernel forces a very large amount of data to disk after letting a lot of\r\nuncommited data build up. In the worst case scenario the OS will stop the process for tens of\r\nseconds at a time ( even up to 40 seconds) rather than let the program continue. However, to get\r\ninto that state you have to be loading a lot of data which exceeds main memory with very little rest\r\n(e.g. cpu processing). There are good use cases for bulk data loads, but you have to be careful how\r\nthis is done if you also want good worst case latency characteristics. (the throughput should be\r\nmuch the same)\r\n\r\nWhen you create a Chronicle Map, it has many segments. By default it has a minimum of 128, but one\r\nfor every 32 K entries. e.g. for 500M entries you can expect ~16K segments (being the next power of\r\n2). With so many segments, the chances of a perfect hash distribution is low and so the Chronicle\r\nMap allows for double what you asked for but is designed to do this with almost no extra main memory\r\n(only extra virtual memory). This means when you ask for 500M * 256 bytes entries you actually get 1\r\nBN possible entries (assuming a perfect hash distribution between segments) There is a small\r\noverhead per entry of 16 - 24 bytes adding another 20 GB.\r\n\r\nSo while the virtual memory is 270 GB, it is expected that for 500 M entries you will be trying to\r\nuse no more than 20 GB (overhead/hash tables) + ~120 GB (entries)\r\n\r\nWhen Chronicle Map has exhausted all the memory on your server, its not going to be so fast, for a\r\nrandom access pattern you are entirely dependant on how fast your underlying disk is. If your home\r\ndirectory is an HDD and its performance is around 125 IOPS (I/Os per second). Each lookup takes two\r\nmemory accesses so you might get around 65 lookups per second. For 100-200K operations you can\r\nexpect around 1600 seconds or 25-50 minutes. If you use an SSD, it can get around 230 K IOPS, or\r\nabout 115 K Chronicle Map lookups per second.\r\n\r\n### Better to use small keys\r\n\r\nIf you put() a small number of large entries into Chronicle Map, you are unlikely to see any\r\nperformance gains over a standard map, So we recommend you use a standard ConcurrentHashMap, unless\r\nyou need Chronicle Maps other features.\r\n\r\nChronicle Map gives better performance for smaller keys and values due to the low overhead per\r\nentry. It can use 1/5th the memory of ConcurrentHashMap. When you have larger entries, the overhead\r\nper entry doesn't matter so much and the relative waste per entry starts to matter. For Example,\r\nChronicle Map assumes every entry is the same size and if you have 10kB-20kB entries the 10K entries\r\ncan be using 20 kB of virtual memory or at least 12 KB of actual memory (since virtual memory turns\r\ninto physical memory in multiples of a page)\r\n\r\nAs the Chronicle Map gets larger the most important factor is the use of CPU cache rather than main\r\nmemory, performance is constrained by the number of cache lines you have to touch to update/read an\r\nentry. For large entries this is much the same as ConcurrentHashMap.  In this case, Chronicle Map is\r\nnot worse than ConcurrentHashMap but not much better.\r\n\r\nFor large key/values it is not total memory use but other factors which matter such as;\r\n- how compact each entry is. Less memory used makes better use of the L3 cache and memory bus which\r\n  is often a bottleneck in highly concurrent applications. \r\n- reduce the impact on GCs. The time to perform  GC and its impact is linear. Moving the bulk of\r\n  your data off heap can dramatically improve throughput not to mention worst case latency.\r\n- Large data structures take a long time to reload and having a persisted store significantly\r\n  reduces restart times.\r\n- data can be shared between processes. This gives you more design options to share between JVMS and\r\n  support short lived tasks without having to use TCP.\r\n- data can be replicated across machines.\r\n\r\n\r\n\r\n\r\n\r\n### ConcurrentHashMap v ChronicleMap\r\nConcurrentHashMap ( CHM ) outperforms Chronicle Map ( CM ) on throughput.  If you don't need\r\nthe extra features SharedHashMap gives you, it is not worth the extra complexity it brings.\r\ni.e. don't use it just because you think it is cool. The test can be found in\r\n[ChronicleMapTest](https://github.com/OpenHFT/Chronicle-Map/blob/master/src/test/java/net/openhft/chronicle/map/ChronicleMapTest.java)\r\nunder testAcquirePerf() and testCHMAcquirePerf()\r\n\r\nChronicle Map out performs ConcurrentHashMap on memory consumption, and worst case latencies.\r\nIt can be used to reduce or eliminate GCs.\r\n\r\n#### Performance Test for many small key-values\r\nThe following performance test consists of string keys of the form \"u:0123456789\" and an int\r\ncounter.  The update increments the counter once in each thread, creating an new entry if required.\r\n\r\n\r\n| Number of entries | Chronicle* Throughput  |  Chronicle RSS  | HashMap* Throughput | HashMap Worst GC pause | HashMap RSS |\r\n|------------------:|---------------:|---------:|---------------:|-------------------:|--------:|\r\n|        10 million |      30 Mupd/s |     ½ GB |     155 Mupd/s |           2.5 secs |    9 GB |\r\n|        50 million |      31 Mupd/s |    3⅓ GB |     120 Mupd/s |           6.9 secs |   28 GB |\r\n|       250 million |      30 Mupd/s |    14 GB |     114 Mupd/s |          17.3 secs |   76 GB |\r\n|      1000 million |      24 Mupd/s |    57 GB |           OOME |            43 secs |      NA |\r\n|      2500 million |      23 Mupd/s |   126 GB |   Did not test |                 NA |      NA |\r\n\r\n_*HashMap refers to ConcurrentHashMap, Chronicle refers to Chronicle Map_\r\n\r\nNotes:\r\n* Chronicle Map was tested with a 32 MB heap, CHM was test with a 100 GB heap.\r\n* The Chronicle Map test had a small minor GC on startup of 0.5 ms, but not during the test.\r\n  This is being investigated.\r\n* Chronicle Map was tested \"writing\" to a tmpfs file system.\r\n\r\n#### How does it perform when persisted?\r\n\r\nChronicle Map also supports persistence. In this regard there is no similar class in the JDK.\r\n\r\n| Number of entries | Chronicle Throughput  |  Chronicle RSS |\r\n|------------------:|---------------:|---------:|\r\n|        10 million |      28 Mupd/s |     ½ GB |\r\n|        50 million |      28 Mupd/s |     9 GB |\r\n|       250 million |      26 Mupd/s |    24 GB |\r\n|      1000 million |     1.3 Mupd/s |    85 GB |\r\n\r\nNotes:\r\n* Persistence was performed at a PCI-SSD which supports up to 230K IOPS and 900 MB/s write speed.\r\n  This test didn't test the card to it's limit until the last test.\r\n* The kernel tuning parameters for write back are important here.\r\n  This explains the suddern drop off and this is being investigated.\r\n\r\nThe sysctl parameters used were approximately 10x the defaults to allow as many operations\r\nto be performed in memory as possible.\r\n\r\n    vm.dirty_background_ratio = 50\r\n    vm.dirty_expire_centisecs = 30000\r\n    vm.dirty_ratio = 90\r\n    vm.dirty_writeback_centisecs = 5000\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}